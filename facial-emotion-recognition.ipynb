{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fer2013for-recognition', 'facial-expression']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, BatchNormalization, GlobalAveragePooling2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import np_utils\n",
    "import keras.backend as k\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../input/facial-expression/fer2013/fer2013.csv'\n",
    "\n",
    "def read_data(filename):\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    first = True\n",
    "    for line in open(filename):\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            row = line.split(',')\n",
    "            Y.append(int(row[0]))\n",
    "            X.append([int(p) for p in row[1].split()])\n",
    "        \n",
    "    X, Y = np.array(X) / 255.0, np.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "X, Y = read_data(filename)\n",
    "num_class = len(set(Y))\n",
    "print(num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D = X.shape\n",
    "X = X.reshape(N, 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=101)\n",
    "y_train = np_utils.to_categorical(y_train, 7)\n",
    "y_test = np_utils.to_categorical(y_test, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 64\n",
    "width, height = 48, 48\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', input_shape=(width, height, 1), data_format='channels_last', kernel_regularizer=l2(0.01)))\n",
    "model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(2*2*2*num_features, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2*2*num_features, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2*num_features, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_class, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 46, 46, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 46, 46, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 23, 23, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 23, 23, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 23, 23, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 23, 23, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 11, 11, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 11, 11, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 11, 11, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 5, 5, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 5,905,863\n",
      "Trainable params: 5,902,151\n",
      "Non-trainable params: 3,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3, verbose=1)\n",
    "early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=8, verbose=1, mode='auto')\n",
    "checkpointer = ModelCheckpoint('../input/model.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "callbacks = [lr_reducer, early_stopper, checkpointer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "448/448 [==============================] - 21s 47ms/step - loss: 2.0083 - acc: 0.2118 - val_loss: 1.8324 - val_acc: 0.2506\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.83238, saving model to ../input/model.h5\n",
      "Epoch 2/100\n",
      "448/448 [==============================] - 17s 37ms/step - loss: 1.8326 - acc: 0.2441 - val_loss: 1.8107 - val_acc: 0.2523\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.83238 to 1.81070, saving model to ../input/model.h5\n",
      "Epoch 3/100\n",
      "448/448 [==============================] - 17s 37ms/step - loss: 1.8158 - acc: 0.2497 - val_loss: 1.8262 - val_acc: 0.2523\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.81070\n",
      "Epoch 4/100\n",
      "448/448 [==============================] - 16s 37ms/step - loss: 1.8013 - acc: 0.2551 - val_loss: 1.8383 - val_acc: 0.2524\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.81070\n",
      "Epoch 5/100\n",
      "448/448 [==============================] - 17s 37ms/step - loss: 1.7678 - acc: 0.2757 - val_loss: 1.7078 - val_acc: 0.2972\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.81070 to 1.70777, saving model to ../input/model.h5\n",
      "Epoch 6/100\n",
      "448/448 [==============================] - 17s 37ms/step - loss: 1.7028 - acc: 0.3142 - val_loss: 1.7162 - val_acc: 0.2895\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.70777\n",
      "Epoch 7/100\n",
      "448/448 [==============================] - 16s 37ms/step - loss: 1.6145 - acc: 0.3582 - val_loss: 1.5620 - val_acc: 0.4039\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.70777 to 1.56196, saving model to ../input/model.h5\n",
      "Epoch 8/100\n",
      "448/448 [==============================] - 16s 37ms/step - loss: 1.5556 - acc: 0.3882 - val_loss: 1.5843 - val_acc: 0.3894\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.56196\n",
      "Epoch 9/100\n",
      "448/448 [==============================] - 16s 37ms/step - loss: 1.5111 - acc: 0.4035 - val_loss: 1.6641 - val_acc: 0.3479\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.56196\n",
      "Epoch 10/100\n",
      "448/448 [==============================] - 16s 37ms/step - loss: 1.4890 - acc: 0.4232 - val_loss: 1.3843 - val_acc: 0.4529\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.56196 to 1.38434, saving model to ../input/model.h5\n",
      "Epoch 11/100\n",
      "448/448 [==============================] - 16s 37ms/step - loss: 1.4632 - acc: 0.4342 - val_loss: 1.3387 - val_acc: 0.4902\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.38434 to 1.33871, saving model to ../input/model.h5\n",
      "Epoch 12/100\n",
      "448/448 [==============================] - 16s 36ms/step - loss: 1.4368 - acc: 0.4516 - val_loss: 1.3324 - val_acc: 0.5043\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.33871 to 1.33243, saving model to ../input/model.h5\n",
      "Epoch 13/100\n",
      "448/448 [==============================] - 16s 37ms/step - loss: 1.4052 - acc: 0.4653 - val_loss: 1.5404 - val_acc: 0.4363\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.33243\n",
      "Epoch 14/100\n",
      "448/448 [==============================] - 17s 38ms/step - loss: 1.3895 - acc: 0.4734 - val_loss: 1.2613 - val_acc: 0.5194\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.33243 to 1.26135, saving model to ../input/model.h5\n",
      "Epoch 15/100\n",
      "448/448 [==============================] - 16s 37ms/step - loss: 1.3606 - acc: 0.4882 - val_loss: 1.2670 - val_acc: 0.5192\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.26135\n",
      "Epoch 16/100\n",
      "448/448 [==============================] - 16s 36ms/step - loss: 1.3455 - acc: 0.4975 - val_loss: 1.2388 - val_acc: 0.5347\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.26135 to 1.23877, saving model to ../input/model.h5\n",
      "Epoch 17/100\n",
      "448/448 [==============================] - 16s 36ms/step - loss: 1.3319 - acc: 0.5032 - val_loss: 1.2965 - val_acc: 0.5242\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.23877\n",
      "Epoch 18/100\n",
      "448/448 [==============================] - 16s 37ms/step - loss: 1.3312 - acc: 0.5064 - val_loss: 1.3998 - val_acc: 0.4607\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.23877\n",
      "Epoch 19/100\n",
      "448/448 [==============================] - 16s 36ms/step - loss: 1.3023 - acc: 0.5169 - val_loss: 1.1630 - val_acc: 0.5614\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.23877 to 1.16303, saving model to ../input/model.h5\n",
      "Epoch 20/100\n",
      "448/448 [==============================] - 16s 37ms/step - loss: 1.2956 - acc: 0.5222 - val_loss: 1.1778 - val_acc: 0.5581\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.16303\n",
      "Epoch 21/100\n",
      "448/448 [==============================] - 16s 36ms/step - loss: 1.2776 - acc: 0.5303 - val_loss: 1.1631 - val_acc: 0.5666\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.16303\n",
      "Epoch 22/100\n",
      "448/448 [==============================] - 16s 36ms/step - loss: 1.2695 - acc: 0.5361 - val_loss: 1.1955 - val_acc: 0.5538\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.16303\n",
      "Epoch 23/100\n",
      "448/448 [==============================] - 16s 36ms/step - loss: 1.2637 - acc: 0.5353 - val_loss: 1.1959 - val_acc: 0.5670\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.16303\n",
      "Epoch 24/100\n",
      "448/448 [==============================] - 16s 37ms/step - loss: 1.2434 - acc: 0.5425 - val_loss: 1.1378 - val_acc: 0.5816\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.16303 to 1.13777, saving model to ../input/model.h5\n",
      "Epoch 25/100\n",
      "448/448 [==============================] - 17s 37ms/step - loss: 1.2288 - acc: 0.5513 - val_loss: 1.1580 - val_acc: 0.5691\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.13777\n",
      "Epoch 26/100\n",
      "448/448 [==============================] - 16s 36ms/step - loss: 1.2278 - acc: 0.5537 - val_loss: 1.1395 - val_acc: 0.5637\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.13777\n",
      "Epoch 27/100\n",
      " 59/448 [==>...........................] - ETA: 13s - loss: 1.1961 - acc: 0.5661"
     ]
    }
   ],
   "source": [
    "# With Augmentation\n",
    "bs = 64\n",
    "epochs = 100\n",
    "\n",
    "aug = ImageDataGenerator(rotation_range=20, \n",
    "                         width_shift_range=0.1, \n",
    "                         height_shift_range=0.1, \n",
    "                         horizontal_flip=True, \n",
    "                         fill_mode=\"nearest\")\n",
    "\n",
    "H = model.fit_generator(aug.flow(x_train, y_train, batch_size=bs),\n",
    "                        validation_data=(x_test, y_test), \n",
    "                        steps_per_epoch=len(x_train)//bs,\n",
    "                        callbacks=callbacks,\n",
    "                        shuffle=True,\n",
    "                        epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7178/7178 [==============================] - 1s 174us/step\n",
      "Loss: 0.9379754525168954\n",
      "Accuracy: 0.6540819169851225\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, batch_size=bs)\n",
    "print(\"Loss: \" + str(scores[0]))\n",
    "print(\"Accuracy: \" + str(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras_preprocessing/image/utils.py:104: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06688503 0.00928699 0.25283882 0.06200942 0.09636712 0.3951489\n",
      " 0.11746369]\n"
     ]
    }
   ],
   "source": [
    "img = image.load_img('../input/fer2013for-recognition/index.jpeg', grayscale=True, target_size=(48, 48))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x /= 255\n",
    "custom = model.predict(x)\n",
    "\n",
    "x = np.array(x, 'float32')\n",
    "x = x.reshape([48, 48]);\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(x)\n",
    "plt.show()\n",
    "print(custom[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surprise\n"
     ]
    }
   ],
   "source": [
    "custom = custom[0]\n",
    "emotion = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "#Find the maximum probablity of a image and select that class\n",
    "lar = 0\n",
    "for i, ele in enumerate(custom):\n",
    "    if ele > lar:\n",
    "        msg = emotion[i]\n",
    "        lar = ele \n",
    "    else:\n",
    "         pass\n",
    "print(msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
